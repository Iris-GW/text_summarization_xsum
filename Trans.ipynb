{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer, T5Config, TrainingArguments, Trainer\n",
    "import wandb\n",
    "import numpy as np\n",
    "from rouge import Rouge\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the XSum dataset\n",
    "dataset = load_dataset(\"xsum\")\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model name and tokenizer\n",
    "model_name = \"t5-small\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_batch(batch):\n",
    "    input_texts = [\"summarize: \" + doc for doc in batch[\"document\"]]\n",
    "    target_texts = batch[\"summary\"]\n",
    "\n",
    "    source = tokenizer(input_texts, max_length=512, truncation=True, padding='max_length', return_tensors=\"pt\")\n",
    "    target = tokenizer(target_texts, max_length=150, truncation=True, padding='max_length', return_tensors=\"pt\")\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": source[\"input_ids\"].tolist(),\n",
    "        \"attention_mask\": source[\"attention_mask\"].tolist(),\n",
    "        \"labels\": target[\"input_ids\"].tolist(),\n",
    "    }\n",
    "\n",
    "tokenized_dataset = dataset.map(preprocess_batch, remove_columns=[\"document\", \"summary\"], batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the T5 model\n",
    "config = T5Config.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name, config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up training and evaluation arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./t5_xsum\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    weight_decay=0.01,\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"wandb\", \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the fine-tuned model\n",
    "trainer.save_model(\"./t5_xsum_finetuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary_transformer(article):\n",
    "    model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
    "    tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "\n",
    "    inputs = tokenizer.encode(\"summarize: \" + article, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "    summary_ids = model.generate(inputs, num_return_sequences=1, max_length=150, no_repeat_ngram_size=2, min_length=30, early_stopping=True)\n",
    "\n",
    "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "def evaluate_model(generate_summary_function):\n",
    "    rouge = Rouge()\n",
    "    bleu_score = 0\n",
    "    dataset = load_dataset('xsum', split='test')\n",
    "    predictions = []\n",
    "    references = []\n",
    "\n",
    "    for example in dataset:\n",
    "        article = example[\"document\"]\n",
    "        summary = generate_summary_function(article)\n",
    "        predictions.append(summary)\n",
    "        references.append(example[\"summary\"])\n",
    "\n",
    "    rouge_scores = rouge.compute(predictions=predictions, references=references, rouge_types=[\"rouge1\", \"rouge2\", \"rougeL\"])\n",
    "\n",
    "    # Compute BLEU score\n",
    "    for pred, ref in zip(predictions, references):\n",
    "        pred_tokens = pred.split()\n",
    "        ref_tokens = ref.split()\n",
    "        bleu_score += sentence_bleu([ref_tokens], pred_tokens, smoothing_function=SmoothingFunction().method1)\n",
    "\n",
    "    bleu_score = bleu_score / len(predictions)\n",
    "\n",
    "    return rouge_scores, bleu_score\n",
    "\n",
    "# Evaluate the Transformer-based model\n",
    "transformer_rouge_scores, transformer_bleu_score = evaluate_model(generate_summary_transformer)\n",
    "print(\"Transformer Rouge Scores:\", transformer_rouge_scores)\n",
    "print(\"Transformer BLEU Score:\", transformer_bleu_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
